## Reading and writing Apache Arrow file format in Java 
In this blog post I am going to show to how to write and 
read Apache Arrow files in a stand-alone Java program.
 
 
Apache Arrow [https://arrow.apache.org/](https://arrow.apache.org/)
is a popular in-memory columnar storage format. It is to memory 
what is parquet/ORC are to disk-oriented columnar storage 
formats. The goals of the project is to standardizes in-memory 
columnar data presentation for all data processing engines (e.g., 
Spark, Drill, Impala, etc.). The standardization helps with reducing 
the communication and serialization overheads, increases shared 
code-base to manage data (e.g., parquet reading to arrow format), 
and promises to improve performance. For more details about Arrow 
please refer to the website. 


## Project setup and dependencies 
All the code I am going to discuss here is available as a maven project 
at 
[https://github.com/animeshtrivedi/ArrowExample](https://github.com/animeshtrivedi/ArrowExample) 

You can specify arrow maven dependency by putting these in the pom file. 

```xml
<dependencies>
 <dependency>
  <groupId>org.apache.arrow</groupId>
  <artifactId>arrow-memory</artifactId>
  <version>0.8.0</version>
 </dependency>

 <dependency>
  <groupId>org.apache.arrow</groupId>
  <artifactId>arrow-vector</artifactId>
  <version>0.8.0</version>
 </dependency>
</dependencies>
```

I highly recommend to use the `0.8` release of arrow. But if you are interested in how 
it can be done with the `0.7` release then check the `0.7-example` branch in the github 
project. 

## Apache Arrow Java writer

We first start with the pertinent writer-side objects that can be found in the ArrowWriter.java 
class in the project. 

### How to make schema
We start with how to define Arrow schema on the writer side. This is done by defining 
 a `Field` object that takes a string name, type, and additional children parameter, 
 if the type is of a complex type (like list, map, etc.). We will be covering simple 
 primitive types in this blog post. A field object of type integer can be defined 
 as:  
 ```
Field intField = new Field("int", FieldType.nullable(new ArrowType.Int(32, true)), null);
 ```
In this example `32` says the bit-width. `true` tells that it is a signed int. And the last 
`null` points out that it has no complex, children. In the `ArrowWriter` class, there are 
more example of how to define long, float, double, etc. Another important primitive type 
to define is a `byte[]` type. Any arbitrary data type can be serialzied to and deserialized 
from `byte[]`. It is done as : 

```java
Field binaryField = new Field("binary", FieldType.nullable(new ArrowType.Binary()), null);
```

Having defined multiple Fields now we have to stich then together to make a schema. This 
can done as simply as 
```java 
ImmutableList.Builder<Field> childrenBuilder = ImmutableList.builder();
childrenBuilder.add(intField);
childrenBuilder.add(binaryField);
...
new Schema(childrenBuilder.build(), null);
```

A `Schema` object constructor only requires an iterable list. 
```java
Schema(Iterable<Field> fields, Map<String, String> metadata);
```

I do not know what is metadata and how is it used. 

### How to write data in Arrow 
#### Setup 
The next important class to understand is `VectorSchemaRoot`. It is responsible for 
managing reader and writer interfaces, memory allocation, and more. So we first allocate 
is as 
```java
VectorSchemaRoot root = VectorSchemaRoot.create(schema, new RootAllocator(Integer.MAX_VALUE));
```
Now the next item on our list is to get a `ArrowFileWriter`. Its constructor is 
```java 
public ArrowFileWriter(VectorSchemaRoot root, DictionaryProvider provider, WritableByteChannel out)
```
We already have `VectorSchemaRoot`. `DictionaryProvider` can be allocated by simply calling 
`new DictionaryProvider.MapDictionaryProvider()`. Dictionary are important when passing a 
reader's data toanother writer which might be dictionary encoded. But here a new dictionary 
will do. And now the `WritableByteChannel`, which is a java abstraction. Default file API in 
java already have an implementation for this which can be obtained simply by calling `getChannel` 
on an `FileOutputStream` object. However, you are free to implement your own as well. As we will 
show later in the blog we do have to write on if you are reading and writing data from HDFS. 
So, at this point we have a `ArrowFileWriter` object. 

The corresponding code for the discussion so far can be found in the `makeWrite` function 
in the `ArrowWrite` class in the example project.   

#### Writing data 
